{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction to `yield` in Python**\n",
    "\n",
    "The `yield` keyword in Python is used to create **generators**, which are a type of iterable that allows you to produce values **lazily**, one at a time, instead of returning all at once like in a list.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Features of `yield`:**\n",
    "\n",
    "1. **State Retention:**\n",
    "   - Unlike `return`, which exits a function completely, `yield` pauses the function and retains its state. The function can be resumed from where it left off.\n",
    "\n",
    "2. **Efficient Memory Usage:**\n",
    "   - Because generators produce items one at a time, they are more memory-efficient than creating and storing all items in memory at once.\n",
    "\n",
    "3. **Simplifies Iterator Creation:**\n",
    "   - Generators eliminate the need for implementing `__iter__()` and `__next__()` methods manually.\n",
    "\n",
    "4. **Use Cases:**\n",
    "   - Generators are ideal for handling large data streams, infinite sequences, or any scenario where you don't need all the data at once.\n",
    "\n",
    "---\n",
    "\n",
    "### **How `yield` Works:**\n",
    "\n",
    "#### **1. Creating a Generator Function:**\n",
    "   - Any function that contains a `yield` statement automatically becomes a generator function.\n",
    "   - Instead of returning a single value, the function generates a series of values, pausing after each `yield`.\n",
    "\n",
    "#### Example:\n",
    "```python\n",
    "def count_up_to(n):\n",
    "    count = 1\n",
    "    while count <= n:\n",
    "        yield count\n",
    "        count += 1\n",
    "\n",
    "# Using the generator\n",
    "for num in count_up_to(5):\n",
    "    print(num)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "1\n",
    "2\n",
    "3\n",
    "4\n",
    "5\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "- The function `count_up_to` pauses at each `yield` and resumes when the next value is requested.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Comparing `yield` vs `return`:**\n",
    "- **`return`**: Ends the function and sends a single value.\n",
    "- **`yield`**: Pauses the function and can return multiple values over time.\n",
    "\n",
    "```python\n",
    "def using_return():\n",
    "    return [1, 2, 3]  # Returns all values at once\n",
    "\n",
    "def using_yield():\n",
    "    yield 1\n",
    "    yield 2\n",
    "    yield 3  # Yields values one at a time\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use `yield`?**\n",
    "\n",
    "1. **Large Datasets:**\n",
    "   - When processing a dataset that is too large to fit in memory, like reading a massive file line by line.\n",
    "   \n",
    "   Example:\n",
    "   ```python\n",
    "   def read_file(file_name):\n",
    "       with open(file_name) as file:\n",
    "           for line in file:\n",
    "               yield line.strip()\n",
    "   ```\n",
    "\n",
    "2. **Infinite Sequences:**\n",
    "   - When you need to generate a potentially infinite series, such as Fibonacci numbers or prime numbers.\n",
    "   \n",
    "   Example:\n",
    "   ```python\n",
    "   def infinite_fibonacci():\n",
    "       a, b = 0, 1\n",
    "       while True:\n",
    "           yield a\n",
    "           a, b = b, a + b\n",
    "   ```\n",
    "\n",
    "3. **Pipelines:**\n",
    "   - When chaining multiple processing steps together, using generators avoids creating intermediate lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'color'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# print(\"End of function\")\u001b[39;00m\n\u001b[1;32m     12\u001b[0m response_api \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLaptop\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     14\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSmart Watch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     15\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCamera\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     16\u001b[0m ]\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mstart_scraping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_api\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m, in \u001b[0;36mstart_scraping\u001b[0;34m(response_api)\u001b[0m\n\u001b[1;32m      4\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m response_api:\n\u001b[0;32m----> 7\u001b[0m     color \u001b[38;5;241m=\u001b[39m \u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# This will trigger error\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(color)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[0;31mKeyError\u001b[0m: 'color'"
     ]
    }
   ],
   "source": [
    "# Example of data lost using return\n",
    "\n",
    "def start_scraping(response_api):\n",
    "    results = []\n",
    "\n",
    "    for i in response_api:\n",
    "        color = i[\"color\"] # This will trigger error\n",
    "        results.append(color)\n",
    "    return results\n",
    "    # print(\"End of function\")\n",
    "\n",
    "response_api = [\n",
    "    {\"ID\": 1, \"item\": \"Laptop\", \"color\": \"black\"},\n",
    "    {\"ID\": 2, \"item\": \"Smart Watch\", \"color\": \"green\"},\n",
    "    {\"ID\": 3, \"item\": \"Camera\"},\n",
    "]\n",
    "\n",
    "print(start_scraping(response_api))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black\n",
      "green\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'color'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Create a generator object\u001b[39;00m\n\u001b[1;32m     16\u001b[0m results \u001b[38;5;241m=\u001b[39m start_scraping(response_api)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m, in \u001b[0;36mstart_scraping\u001b[0;34m(response_api)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstart_scraping\u001b[39m(response_api):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m response_api:\n\u001b[0;32m----> 5\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'color'"
     ]
    }
   ],
   "source": [
    "# Example of data retrieved with yield\n",
    "\n",
    "def start_scraping(response_api):\n",
    "    for i in response_api:\n",
    "        yield i[\"color\"] # This will trigger error\n",
    "        # print(\"End of function\")\n",
    "\n",
    "# Dummy data\n",
    "response_api = [\n",
    "    {\"ID\": 1, \"item\": \"Laptop\", \"color\": \"black\"},\n",
    "    {\"ID\": 2, \"item\": \"Smart Watch\", \"color\": \"green\"},\n",
    "    {\"ID\": 3, \"item\": \"Camera\"},\n",
    "]\n",
    "\n",
    "# Create a generator object\n",
    "results = start_scraping(response_api)\n",
    "\n",
    "for i in results:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8856\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "# Compare the size of a list and a generator\n",
    "import sys\n",
    "\n",
    "example_list = [i for i in range(1000)]\n",
    "example_generator = (i for i in range(1000))\n",
    "\n",
    "print(sys.getsizeof(example_list))\n",
    "print(sys.getsizeof(example_generator))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Understanding the difference between a funtion and a generator\n",
    "\"\"\"\n",
    "list_data = [i for i in range(10)]\n",
    "\n",
    "# TODO: \n",
    "# 1. Create a function that reverse a list manually, without reverse method\n",
    "# 2. Execute your function using list_data as the input parameter\n",
    "# 3. Check your function by printing them\n",
    "# 4. Print all of the item using loop\n",
    "\n",
    "def reverse_list_data(list_data:list[int]) -> list[int]:\n",
    "    results = []\n",
    "    n = len(list_data)-1\n",
    "    while n >= 0 :\n",
    "        results.append(list_data[n])\n",
    "        n-=1\n",
    "    return results\n",
    "\n",
    "print(reverse_list_data(list_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Understanding the difference between a funtion and a generator\n",
    "\"\"\"\n",
    "# TODO: \n",
    "# 1. Re-create previous function using yield\n",
    "# 2. Execute your function using list_data as the input parameter\n",
    "# 3. Check your function by printing them\n",
    "# 4. Print all of the item using loop\n",
    "# 5. Analyze the difference between them\n",
    "\n",
    "def reverse_list_data(list_data:list[int]):\n",
    "    n = len(list_data)-1\n",
    "    while n >= 0 :\n",
    "        yield list_data[n]\n",
    "        n-=1\n",
    "\n",
    "for i in reverse_list_data(list_data):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'books_urls.csv' with 1000000 dynamic URLs has been created.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Execute this cell and take a look at csv file before continue\n",
    "import csv\n",
    "\n",
    "def create_csv(file_name, base_url, num_entries):\n",
    "    with open(file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write header\n",
    "        writer.writerow([\"ID\", \"URL\"])\n",
    "        \n",
    "        # Write rows with dynamically generated URLs\n",
    "        for i in range(1, num_entries + 1):\n",
    "            # Replace \"page-20.html\" with the current ID\n",
    "            dynamic_url = base_url + f\"/catalogue/page-{i}.html\"\n",
    "            writer.writerow([i, dynamic_url])\n",
    "    \n",
    "    print(f\"CSV file '{file_name}' with {num_entries} dynamic URLs has been created.\")\n",
    "\n",
    "create_csv(\n",
    "    file_name=\"books_urls.csv\",\n",
    "    base_url=\"https://books.toscrape.com\",\n",
    "    num_entries=1000000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting https://books.toscrape.com/catalogue/page-1.html\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\u001b[38;5;241m.\u001b[39mstatus_code  \u001b[38;5;66;03m# Send a GET request and get the status code\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# Raise an exception to intentionally halt the program (for testing purposes)\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# TODO: Take a look at how long it takes before raising error\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Compare the speed of scraping execution from huge file of csv\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "def read_urls_from_csv(file_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file and returns a list of URLs found in the 'URL' column.\n",
    "    \"\"\"\n",
    "    urls = []  # Initialize an empty list to store URLs\n",
    "    with open(file_path, mode='r') as file:\n",
    "        # Create a CSV reader object to parse the CSV file\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        \n",
    "        # Iterate through each row in the CSV file\n",
    "        for row in csv_reader:\n",
    "            # Append the value in the 'URL' column to the urls list\n",
    "            urls.append(row[\"URL\"])\n",
    "    \n",
    "    return urls  # Return the list of URLs\n",
    "\n",
    "# Read the URLs from the CSV file into the data_csv list\n",
    "data_csv = read_urls_from_csv('books_urls.csv')\n",
    "\n",
    "# Iterate through each URL in the list\n",
    "for url in data_csv:\n",
    "    print(f\"Getting {url}\")  # Print a message indicating the URL being fetched\n",
    "    response = requests.get(url).status_code  # Send a GET request and get the status code\n",
    "    \n",
    "    # Raise an exception to intentionally halt the program (for testing purposes)\n",
    "    raise\n",
    "\n",
    "# TODO: Take a look at how long it takes before raising error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting https://books.toscrape.com/catalogue/page-1.html\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\u001b[38;5;241m.\u001b[39mstatus_code  \u001b[38;5;66;03m# Send a GET request and get the status code\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Raise an exception to intentionally halt the program (for testing purposes)\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Compare the speed of scraping execution from huge file of csv\n",
    "\"\"\"\n",
    "# TODO:\n",
    "# 1. Re-create previous function by using yield\n",
    "# 2. Compare the time execution and give your insight\n",
    "\n",
    "def read_urls_from_csv(file_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file and returns a list of URLs found in the 'URL' column.\n",
    "    \"\"\"\n",
    "    with open(file_path, mode='r') as file:\n",
    "        # Create a CSV reader object to parse the CSV file\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        \n",
    "        # Iterate through each row in the CSV file\n",
    "        for row in csv_reader:\n",
    "            # Append the value in the 'URL' column to the urls list\n",
    "            yield row[\"URL\"]\n",
    "\n",
    "# Iterate through each URL in the list\n",
    "for url in read_urls_from_csv('books_urls.csv'):\n",
    "    print(f\"Getting {url}\")  # Print a message indicating the URL being fetched\n",
    "    response = requests.get(url).status_code  # Send a GET request and get the status code\n",
    "    \n",
    "    # Raise an exception to intentionally halt the program (for testing purposes)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://books.toscrape.com/catalogue/page-1.html\n",
      "Scraping: https://books.toscrape.com/catalogue/page-10.html\n",
      "Scraping: https://books.toscrape.com/catalogue/page-200.html\n",
      "Exception error: 404 Client Error: Not Found for url: https://books.toscrape.com/catalogue/page-200.html\n",
      "Scraping: https://books.toscrape.com/catalogue/page-20.html\n",
      "https://books.toscrape.com/a-light-in-the-attic_1000/index.html\n",
      "https://books.toscrape.com/tipping-the-velvet_999/index.html\n",
      "https://books.toscrape.com/soumission_998/index.html\n",
      "https://books.toscrape.com/sharp-objects_997/index.html\n",
      "https://books.toscrape.com/sapiens-a-brief-history-of-humankind_996/index.html\n",
      "https://books.toscrape.com/the-requiem-red_995/index.html\n",
      "https://books.toscrape.com/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html\n",
      "https://books.toscrape.com/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html\n",
      "https://books.toscrape.com/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html\n",
      "https://books.toscrape.com/the-black-maria_991/index.html\n",
      "https://books.toscrape.com/starving-hearts-triangular-trade-trilogy-1_990/index.html\n",
      "https://books.toscrape.com/shakespeares-sonnets_989/index.html\n",
      "https://books.toscrape.com/set-me-free_988/index.html\n",
      "https://books.toscrape.com/scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html\n",
      "https://books.toscrape.com/rip-it-up-and-start-again_986/index.html\n",
      "https://books.toscrape.com/our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html\n",
      "https://books.toscrape.com/olio_984/index.html\n",
      "https://books.toscrape.com/mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html\n",
      "https://books.toscrape.com/libertarianism-for-beginners_982/index.html\n",
      "https://books.toscrape.com/its-only-the-himalayas_981/index.html\n",
      "https://books.toscrape.com/modern-romance_820/index.html\n",
      "https://books.toscrape.com/miss-peregrines-home-for-peculiar-children-miss-peregrines-peculiar-children-1_819/index.html\n",
      "https://books.toscrape.com/louisa-the-extraordinary-life-of-mrs-adams_818/index.html\n",
      "https://books.toscrape.com/little-red_817/index.html\n",
      "https://books.toscrape.com/library-of-souls-miss-peregrines-peculiar-children-3_816/index.html\n",
      "https://books.toscrape.com/large-print-heart-of-the-pride_815/index.html\n",
      "https://books.toscrape.com/i-had-a-nice-time-and-other-lies-how-to-find-love-sht-like-that_814/index.html\n",
      "https://books.toscrape.com/hollow-city-miss-peregrines-peculiar-children-2_813/index.html\n",
      "https://books.toscrape.com/grumbles_812/index.html\n",
      "https://books.toscrape.com/full-moon-over-noahs-ark-an-odyssey-to-mount-ararat-and-beyond_811/index.html\n",
      "https://books.toscrape.com/frostbite-vampire-academy-2_810/index.html\n",
      "https://books.toscrape.com/follow-you-home_809/index.html\n",
      "https://books.toscrape.com/first-steps-for-new-christians-print-edition_808/index.html\n",
      "https://books.toscrape.com/finders-keepers-bill-hodges-trilogy-2_807/index.html\n",
      "https://books.toscrape.com/fables-vol-1-legends-in-exile-fables-1_806/index.html\n",
      "https://books.toscrape.com/eureka-trivia-60_805/index.html\n",
      "https://books.toscrape.com/drive-the-surprising-truth-about-what-motivates-us_804/index.html\n",
      "https://books.toscrape.com/done-rubbed-out-reightman-bailey-1_803/index.html\n",
      "https://books.toscrape.com/doing-it-over-most-likely-to-1_802/index.html\n",
      "https://books.toscrape.com/deliciously-ella-every-day-quick-and-easy-recipes-for-gluten-free-snacks-packed-lunches-and-simple-meals_801/index.html\n",
      "https://books.toscrape.com/hide-away-eve-duncan-20_620/index.html\n",
      "https://books.toscrape.com/furiously-happy-a-funny-book-about-horrible-things_619/index.html\n",
      "https://books.toscrape.com/everyday-italian-125-simple-and-delicious-recipes_618/index.html\n",
      "https://books.toscrape.com/equal-is-unfair-americas-misguided-fight-against-income-inequality_617/index.html\n",
      "https://books.toscrape.com/eleanor-park_616/index.html\n",
      "https://books.toscrape.com/dirty-dive-bar-1_615/index.html\n",
      "https://books.toscrape.com/can-you-keep-a-secret-fear-street-relaunch-4_614/index.html\n",
      "https://books.toscrape.com/boar-island-anna-pigeon-19_613/index.html\n",
      "https://books.toscrape.com/a-paris-apartment_612/index.html\n",
      "https://books.toscrape.com/a-la-mode-120-recipes-in-60-pairings-pies-tarts-cakes-crisps-and-more-topped-with-ice-cream-gelato-frozen-custard-and-more_611/index.html\n",
      "https://books.toscrape.com/troublemaker-surviving-hollywood-and-scientology_610/index.html\n",
      "https://books.toscrape.com/the-widow_609/index.html\n",
      "https://books.toscrape.com/the-sleep-revolution-transforming-your-life-one-night-at-a-time_608/index.html\n",
      "https://books.toscrape.com/the-improbability-of-love_607/index.html\n",
      "https://books.toscrape.com/the-art-of-startup-fundraising_606/index.html\n",
      "https://books.toscrape.com/take-me-home-tonight-rock-star-romance-3_605/index.html\n",
      "https://books.toscrape.com/sleeping-giants-themis-files-1_604/index.html\n",
      "https://books.toscrape.com/setting-the-world-on-fire-the-brief-astonishing-life-of-st-catherine-of-siena_603/index.html\n",
      "https://books.toscrape.com/playing-with-fire_602/index.html\n",
      "https://books.toscrape.com/off-the-hook-fishing-for-trouble-1_601/index.html\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Using yield for scraping\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "\n",
    "# Scrape product data from a list of URLs\n",
    "def scrape_product_urls(urls):\n",
    "    \"\"\"\n",
    "    Scrape product URLs from a list of pages.\n",
    "    \"\"\"\n",
    "    all_product_urls = []\n",
    "    for url in urls:\n",
    "        print(f\"Scraping: {url}\")\n",
    "\n",
    "        # TODO: \n",
    "        # 1. Get the html response of the page url\n",
    "        # 2. Extract the items url into all_product_urls\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, timeout=5)\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.Timeout as et:\n",
    "            print(\"Error Timeout : {et}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Exception error:\", e)\n",
    "            \n",
    "        soup = bs(response.text, 'html.parser')\n",
    "        divs = soup.find_all('div', class_='image_container')\n",
    "        \n",
    "        for d in divs:\n",
    "            p_url = f\"https://books.toscrape.com/{d.find('a')['href']}\"\n",
    "            all_product_urls.append(p_url)\n",
    "\n",
    "\n",
    "\n",
    "    return all_product_urls\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    page_urls = [\n",
    "        \"https://books.toscrape.com/catalogue/page-1.html\",\n",
    "        \"https://books.toscrape.com/catalogue/page-10.html\",\n",
    "        \"https://books.toscrape.com/catalogue/page-200.html\",\n",
    "        \"https://books.toscrape.com/catalogue/page-20.html\"\n",
    "    ]\n",
    "    product_items = scrape_product_urls(page_urls)\n",
    "\n",
    "    # Print the extracted product URLs\n",
    "    for item in product_items:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://books.toscrape.com/catalogue/page-1.html\n",
      "https://books.toscrape.com/a-light-in-the-attic_1000/index.html\n",
      "https://books.toscrape.com/tipping-the-velvet_999/index.html\n",
      "https://books.toscrape.com/soumission_998/index.html\n",
      "https://books.toscrape.com/sharp-objects_997/index.html\n",
      "https://books.toscrape.com/sapiens-a-brief-history-of-humankind_996/index.html\n",
      "https://books.toscrape.com/the-requiem-red_995/index.html\n",
      "https://books.toscrape.com/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html\n",
      "https://books.toscrape.com/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html\n",
      "https://books.toscrape.com/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html\n",
      "https://books.toscrape.com/the-black-maria_991/index.html\n",
      "https://books.toscrape.com/starving-hearts-triangular-trade-trilogy-1_990/index.html\n",
      "https://books.toscrape.com/shakespeares-sonnets_989/index.html\n",
      "https://books.toscrape.com/set-me-free_988/index.html\n",
      "https://books.toscrape.com/scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html\n",
      "https://books.toscrape.com/rip-it-up-and-start-again_986/index.html\n",
      "https://books.toscrape.com/our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html\n",
      "https://books.toscrape.com/olio_984/index.html\n",
      "https://books.toscrape.com/mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html\n",
      "https://books.toscrape.com/libertarianism-for-beginners_982/index.html\n",
      "https://books.toscrape.com/its-only-the-himalayas_981/index.html\n",
      "Scraping: https://books.toscrape.com/catalogue/page-10.html\n",
      "https://books.toscrape.com/modern-romance_820/index.html\n",
      "https://books.toscrape.com/miss-peregrines-home-for-peculiar-children-miss-peregrines-peculiar-children-1_819/index.html\n",
      "https://books.toscrape.com/louisa-the-extraordinary-life-of-mrs-adams_818/index.html\n",
      "https://books.toscrape.com/little-red_817/index.html\n",
      "https://books.toscrape.com/library-of-souls-miss-peregrines-peculiar-children-3_816/index.html\n",
      "https://books.toscrape.com/large-print-heart-of-the-pride_815/index.html\n",
      "https://books.toscrape.com/i-had-a-nice-time-and-other-lies-how-to-find-love-sht-like-that_814/index.html\n",
      "https://books.toscrape.com/hollow-city-miss-peregrines-peculiar-children-2_813/index.html\n",
      "https://books.toscrape.com/grumbles_812/index.html\n",
      "https://books.toscrape.com/full-moon-over-noahs-ark-an-odyssey-to-mount-ararat-and-beyond_811/index.html\n",
      "https://books.toscrape.com/frostbite-vampire-academy-2_810/index.html\n",
      "https://books.toscrape.com/follow-you-home_809/index.html\n",
      "https://books.toscrape.com/first-steps-for-new-christians-print-edition_808/index.html\n",
      "https://books.toscrape.com/finders-keepers-bill-hodges-trilogy-2_807/index.html\n",
      "https://books.toscrape.com/fables-vol-1-legends-in-exile-fables-1_806/index.html\n",
      "https://books.toscrape.com/eureka-trivia-60_805/index.html\n",
      "https://books.toscrape.com/drive-the-surprising-truth-about-what-motivates-us_804/index.html\n",
      "https://books.toscrape.com/done-rubbed-out-reightman-bailey-1_803/index.html\n",
      "https://books.toscrape.com/doing-it-over-most-likely-to-1_802/index.html\n",
      "https://books.toscrape.com/deliciously-ella-every-day-quick-and-easy-recipes-for-gluten-free-snacks-packed-lunches-and-simple-meals_801/index.html\n",
      "Scraping: https://books.toscrape.com/catalogue/page-200.html\n",
      "Exception error: 404 Client Error: Not Found for url: https://books.toscrape.com/catalogue/page-200.html\n",
      "Scraping: https://books.toscrape.com/catalogue/page-20.html\n",
      "https://books.toscrape.com/hide-away-eve-duncan-20_620/index.html\n",
      "https://books.toscrape.com/furiously-happy-a-funny-book-about-horrible-things_619/index.html\n",
      "https://books.toscrape.com/everyday-italian-125-simple-and-delicious-recipes_618/index.html\n",
      "https://books.toscrape.com/equal-is-unfair-americas-misguided-fight-against-income-inequality_617/index.html\n",
      "https://books.toscrape.com/eleanor-park_616/index.html\n",
      "https://books.toscrape.com/dirty-dive-bar-1_615/index.html\n",
      "https://books.toscrape.com/can-you-keep-a-secret-fear-street-relaunch-4_614/index.html\n",
      "https://books.toscrape.com/boar-island-anna-pigeon-19_613/index.html\n",
      "https://books.toscrape.com/a-paris-apartment_612/index.html\n",
      "https://books.toscrape.com/a-la-mode-120-recipes-in-60-pairings-pies-tarts-cakes-crisps-and-more-topped-with-ice-cream-gelato-frozen-custard-and-more_611/index.html\n",
      "https://books.toscrape.com/troublemaker-surviving-hollywood-and-scientology_610/index.html\n",
      "https://books.toscrape.com/the-widow_609/index.html\n",
      "https://books.toscrape.com/the-sleep-revolution-transforming-your-life-one-night-at-a-time_608/index.html\n",
      "https://books.toscrape.com/the-improbability-of-love_607/index.html\n",
      "https://books.toscrape.com/the-art-of-startup-fundraising_606/index.html\n",
      "https://books.toscrape.com/take-me-home-tonight-rock-star-romance-3_605/index.html\n",
      "https://books.toscrape.com/sleeping-giants-themis-files-1_604/index.html\n",
      "https://books.toscrape.com/setting-the-world-on-fire-the-brief-astonishing-life-of-st-catherine-of-siena_603/index.html\n",
      "https://books.toscrape.com/playing-with-fire_602/index.html\n",
      "https://books.toscrape.com/off-the-hook-fishing-for-trouble-1_601/index.html\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Objective: Using yield for scraping\n",
    "\"\"\"\n",
    "# TODO: \n",
    "# 1. Update previous code by using yield\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "\n",
    "# Scrape product data from a list of URLs\n",
    "def scrape_product_urls(urls):\n",
    "    \"\"\"\n",
    "    Scrape product URLs from a list of pages.\n",
    "    \"\"\"\n",
    "    \n",
    "    for url in urls:\n",
    "        print(f\"Scraping: {url}\")\n",
    "\n",
    "        # TODO: \n",
    "        # 1. Get the html response of the page url\n",
    "        # 2. Extract the items url into all_product_urls\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, timeout=5)\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.Timeout as et:\n",
    "            print(\"Error Timeout : {et}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Exception error:\", e)\n",
    "            \n",
    "        soup = bs(response.text, 'html.parser')\n",
    "        divs = soup.find_all('div', class_='image_container')\n",
    "        \n",
    "        for d in divs:\n",
    "            yield f\"https://books.toscrape.com/{d.find('a')['href']}\"\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    page_urls = [\n",
    "        \"https://books.toscrape.com/catalogue/page-1.html\",\n",
    "        \"https://books.toscrape.com/catalogue/page-10.html\",\n",
    "        \"https://books.toscrape.com/catalogue/page-200.html\",\n",
    "        \"https://books.toscrape.com/catalogue/page-20.html\"\n",
    "    ]\n",
    "\n",
    "    # Print the extracted product URLs\n",
    "    for item in scrape_product_urls(page_urls):\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Objective: Using yield for scraping\n",
    "\"\"\"\n",
    "# TODO:\n",
    "# 1. From your last assignment, update your code by using yield\n",
    "# 2. Create a new branch and push into github\n",
    "# 3. Put the URL here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reflection**\n",
    "If you have a lot of memory, do you think you still need a generator? Give me your reason!\n",
    "\n",
    "depending on the conditions, if the data is large and does not require indexing and the data will not be reprocessed it might be better to use yield otherwise it is better to use a regular return list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploration**\n",
    "In Python, generators and iterators are both essential tools for working with sequences of data. However, we only covers the generators topic here. Explore about the iterators!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
