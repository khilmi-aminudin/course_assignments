{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Transformations**\n",
    "Web scraping often results in raw, messy data that can be inconsistent, incomplete, or improperly formatted. This unrefined data typically includes issues like missing values, typographical errors, varied date formats, and numeric values stored as text. Data transformation is the process of cleaning and standardizing this data using tools such as Pandas, which converts the raw output into a structured DataFrame. Through transformation, we can trim unnecessary whitespace, correct inconsistent casing, fill in missing values, and convert data types appropriately, ensuring that the data is accurate and ready for further analysis.\n",
    "\n",
    "In summary, mastering data transformation techniques is essential for web scrapers to unlock the full potential of their collected data and to facilitate a seamless transition from raw data to actionable insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Execute this cell to get a CSV file to work with\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "scraping_data = [\n",
    "    {\"name\": \"Alice\", \"age\": \"25\", \"email\": \"alice@example.com\", \"rate\": \"$20.5\", \"join_date\": \"2004-01-10\"}, # rate is a string\n",
    "    {\"name\": \"bob\", \"age\": \"30\", \"email\": \"my email is bob30@example.com\", \"rate\": \"$35\", \"join_date\": \"2020/01/12\"},   # email typo, different date format\n",
    "    {\"name\": \"Charlie\", \"age\": \"20\", \"email\": \"charlie@example.com\", \"rate\": \"$20\", \"join_date\": \"2004-01-15\"},  # age missing, non-numeric price\n",
    "    {\"name\": \"David\", \"age\": \"40\", \"email\": \"\", \"rate\": \"45.0\", \"join_date\": \"2004-01-15\"},  # missing email\n",
    "    {\"name\": None, \"age\": None, \"email\": None, \"rate\": None, \"join_date\": None},  # invalid data row\n",
    "    {\"name\": \"Frank\", \"age\": \"35\", \"email\": \"frank@example.com\", \"rate\": 20, \"join_date\": \"2004-01-25\"},\n",
    "    {\"name\": \"Grace\", \"age\": \"28\", \"email\": \"grace@example.com\", \"rate\": 30, \"join_date\": \"2004-12-01\"} \n",
    "]\n",
    "\n",
    "df = pd.DataFrame(scraping_data)\n",
    "df.to_csv(\"scraping_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: Reading data from a CSV file\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Read the data from the CSV file into a DataFrame\n",
    "# TODO: Apart from the read_csv() method, what else can pandas read from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: Understanding the data\n",
    "\"\"\"\n",
    "# TODO: Use the info() and describe(include=\"all\") methods to understand the data\n",
    "# TODO: The info() method returns different non-null values, why is that?\n",
    "# TODO: The describe() method returns 7 count name and 7 unique name, what is that means?\n",
    "\n",
    "print(df.info())\n",
    "# prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.\n",
    "\n",
    "print(df.describe(include=\"all\"))\n",
    "# display summary statistics of numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: Handling missing data\n",
    "Resource: https://www.kaggle.com/code/rtatman/data-cleaning-challenge-handling-missing-values\n",
    "\"\"\"\n",
    "# TODO: Print the dataframe and notice which columns have missing values\n",
    "# TODO: Add a separator print(\"======================================\")\n",
    "# TODO: Remove all the rows that contain a missing value using the dropna() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: Manipulating Textual Data\n",
    "\"\"\"\n",
    "# TODO: Replace all the $ signs with nothing using str.replace\n",
    "# TODO: Shows the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: Manipulating Textual Data\n",
    "\"\"\"\n",
    "# TODO: Replace all the / signs with - using str.replace\n",
    "# TODO: Shows the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: Manipulating Textual Data\n",
    "\"\"\"\n",
    "# TODO: Validate emails from the email column\n",
    "# TODO: Shows the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: Filling Missing Data\n",
    "\"\"\"\n",
    "# TODO: Fill empty value in the email column with \"-\"\n",
    "# TODO: Shows the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: Convert Data Types\n",
    "\"\"\"\n",
    "# TODO: Check the data types of each column using the info() method\n",
    "df.info()\n",
    "\n",
    "df_copy = df.copy()\n",
    "\n",
    "df_copy[\"name\"] = df_copy[\"name\"].astype(\"string\") # this will convert the name column to string\n",
    "df_copy[\"age\"] = df_copy[\"age\"].astype(\"int\") # this will convert the age column to integer\n",
    "df_copy[\"join_date\"] = pd.to_datetime(df_copy[\"join_date\"]) # this will convert the join_date column to datetime\n",
    "\n",
    "# TODO: Convert email column to string\n",
    "# TODO: Convert rate column to float\n",
    "# TODO: Check the data types of each column using the info() method to make sure the conversion was successful\n",
    "\n",
    "# Expected Output\n",
    "# <class 'pandas.core.frame.DataFrame'>\n",
    "# Index: 6 entries, 0 to 6\n",
    "# Data columns (total 5 columns):\n",
    "#  #   Column     Non-Null Count  Dtype         \n",
    "# ---  ------     --------------  -----         \n",
    "#  0   name       6 non-null      string        \n",
    "#  1   age        6 non-null      int64         \n",
    "#  2   email      6 non-null      string        \n",
    "#  3   rate       6 non-null      float64       \n",
    "#  4   join_date  6 non-null      datetime64[ns]\n",
    "# dtypes: datetime64[ns](1), float64(1), int64(1), string(2)\n",
    "# memory usage: 288.0 bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: Add new columns based on existing columns\n",
    "\"\"\"\n",
    "\n",
    "today = pd.to_datetime(\"today\") # get the current date\n",
    "df['period of employment'] = df['join_date'].apply(lambda x: (today - x).days) # this will calculate the period of employment in days\n",
    "\n",
    "# TODO: Re-assign apply() to calculate the period of employment in years\n",
    "# TODO: Re-assign apply() to round up the period of employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: Transpose Rows and Columns\n",
    "\"\"\"\n",
    "# TODO: Execute this cell before continue\n",
    "\n",
    "# Sample data (as rows)\n",
    "data = {\n",
    "    'Attribute': ['Price', 'Change', 'Volume'],\n",
    "    'Apple': [150.00, '+2%', '1M'],\n",
    "    'Microsoft': [250.00, '-1%', '500K'],\n",
    "    'Google': [2800.00, '+1%', '2M']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: Transpose Rows and Columns\n",
    "\"\"\"\n",
    "# TODO: Transpose the DataFrame using the transpose() method\n",
    "# TODO: Shows the result\n",
    "# TODO: Rename the column headers to be the values from the first row\n",
    "# TODO: Drop the first row, reset the index before dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: Understanding Concatenation (pd.concat): Stack DataFrames vertically (rows) or horizontally (columns).\n",
    "\"\"\"\n",
    "# Create first DataFrame\n",
    "df1 = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie']\n",
    "})\n",
    "\n",
    "# Create second DataFrame\n",
    "df2 = pd.DataFrame({\n",
    "    'ID': [4, 5, 6],\n",
    "    'Name': ['David', 'Eva', 'Frank']\n",
    "})\n",
    "\n",
    "# Concatenate vertically (row-wise)\n",
    "df_concat = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "print(df1)\n",
    "print(\"===============================\")\n",
    "print(df2)\n",
    "print(\"===============================\")\n",
    "print(df_concat)\n",
    "print(\"===============================\")\n",
    "\n",
    "# TODO: Execute this cell to understand the before and after concatenation\n",
    "# TODO: Re-apply concatenation vertically to add Age and City columns from df3 below by using axis=1 and set ignore_index=False\n",
    "\n",
    "# Create third DataFrame\n",
    "df3 = pd.DataFrame({\n",
    "    'Age': [25, 30, 35, 25, 30, 35],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Los Angeles', 'Chicago']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: Understanding Merging (pd.merge): Join DataFrames based on common column values (like SQL joins).\n",
    "\"\"\"\n",
    "# Create first DataFrame\n",
    "df1 = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie']\n",
    "})\n",
    "\n",
    "# Create second DataFrame\n",
    "df2 = pd.DataFrame({\n",
    "    'ID': [2, 3, 4],\n",
    "    'Age': [30, 35, 40]\n",
    "})\n",
    "\n",
    "# Merge DataFrames on 'ID' (inner join by default)\n",
    "df_merged = pd.merge(df1, df2, on='ID', how='inner')\n",
    "\n",
    "print(df1)\n",
    "print(\"===============================\")\n",
    "print(df2)\n",
    "print(\"===============================\")\n",
    "print(df_merged)\n",
    "\n",
    "# TODO: Execute this cell to understand the inner join in pandas\n",
    "# TODO: After that change how='inner' to how='outer' to understand the outer join\n",
    "# TODO: What is the difference between inner join and outer join?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: Understanding Joining (df.join): Join DataFrames based on index.\n",
    "\"\"\"\n",
    "# Create first DataFrame with custom index\n",
    "df1 = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie']\n",
    "}, index=[1, 2, 3])\n",
    "\n",
    "# Create second DataFrame with matching index\n",
    "df2 = pd.DataFrame({\n",
    "    'Age': [25, 30, 35]\n",
    "}, index=[2, 3, 4])\n",
    "\n",
    "# Join DataFrames on index\n",
    "df_joined = df1.join(df2)\n",
    "\n",
    "print(df1)\n",
    "print(\"===============================\")\n",
    "print(df2)\n",
    "print(\"===============================\")\n",
    "print(df_joined)\n",
    "\n",
    "# TODO: Execute this cell to understand the join in pandas\n",
    "# TODO: Create third dataframe with different index\n",
    "# TODO: Join DataFrames using join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: Choosing between concat, merge, and join\n",
    "\"\"\"\n",
    "# Create first DataFrame (2021 Sales Report)\n",
    "df_2021 = pd.DataFrame({\n",
    "    'Product': ['A', 'B', 'C'],\n",
    "    'Sales': [1200, 1500, 1300],\n",
    "    'Revenue': [24000, 30000, 26000],\n",
    "    'Expenses': [15000, 18000, 16000],\n",
    "    'Profit': [9000, 12000, 10000]\n",
    "})\n",
    "\n",
    "# Create second DataFrame (2022 Sales Report)\n",
    "df_2022 = pd.DataFrame({\n",
    "    'Product': ['A', 'B', 'C'],\n",
    "    'Sales': [1250, 1600, 1350],\n",
    "    'Revenue': [25000, 32000, 27000],\n",
    "    'Expenses': [16000, 19000, 17000],\n",
    "    'Profit': [9000, 13000, 10000]\n",
    "})\n",
    "\n",
    "# Create third DataFrame (2023 Sales Report)\n",
    "df_2023 = pd.DataFrame({\n",
    "    'Product': ['A', 'B', 'C'],\n",
    "    'Sales': [1300, 1700, 1400],\n",
    "    'Revenue': [26000, 34000, 28000],\n",
    "    'Expenses': [17000, 20000, 18000],\n",
    "    'Profit': [9000, 14000, 10000]\n",
    "})\n",
    "\n",
    "# Display DataFrames\n",
    "print(\"2021 Sales Report:\")\n",
    "print(df_2021)\n",
    "print(\"\\n2022 Sales Report:\")\n",
    "print(df_2022)\n",
    "print(\"\\n2023 Sales Report:\")\n",
    "print(df_2023)\n",
    "\n",
    "# TODO: There are 3 difference dataframe, this are representing sales report in a year. Each year they have different file.\n",
    "# TODO: Your task is to combine them into single dataframe for further analysis\n",
    "# TODO: Determine how you combine them. You can choose between concat, merge, and join.\n",
    "# Concatenate DataFrames vertically, with year as a new column to identify the year\n",
    "df_2021['Year'] = 2021\n",
    "df_2022['Year'] = 2022\n",
    "df_2023['Year'] = 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reflection**\n",
    "When would you choose to use pd.concat() instead of pd.merge() or df.join()? And how do the performance and functionality of these methods differ when dealing with large datasets?\n",
    "\n",
    "(answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploration**\n",
    "Learn how to store web-scraped data or any Pandas DataFrame into a Google Spreadsheet programmatically using Google Sheets API and gspread library."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course_assignments-W1NPJChe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
